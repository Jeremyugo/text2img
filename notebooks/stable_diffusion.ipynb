{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c8362ce-86df-47c6-a39b-492355aaac64",
   "metadata": {},
   "source": [
    "# Text-to-Image library (Stable Diffusion)\n",
    "\n",
    "Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images given any text prompt as input. The model was created by the researchers and engineers from CompVis, Stability AI, runway, and LAION.\n",
    "\n",
    "For more information about how Stable Diffusion functions, please go through [ðŸ¤—'s Stable Diffusion with ðŸ§¨Diffusers blog](https://huggingface.co/blog/stable_diffusion).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fb8470-4f58-45df-9e33-938d9cbc2193",
   "metadata": {},
   "source": [
    "- check if you can access GPU from docker JupyterLab container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e7339e-2663-4be5-83f0-7af6eedd5d89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dcda14-0b99-4401-b924-52c89d3812cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Import required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062d8458-9724-4f1d-b8e7-27a2c54a3b91",
   "metadata": {
    "tags": []
   },
   "source": [
    "- [ðŸ¤— ðŸ§¨Diffusers](https://huggingface.co/docs/diffusers/index) provides pretrained vision and audio diffusion models and a great toolset for inference and training\n",
    "\n",
    "- `StableDiffusionPipeline` is an end-to-end inference pipeline that you can use to generate images from text with just a few lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b0ba16-26a3-4b28-b3d3-220510134b2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9f745b-0241-4d63-b0e7-925be491886e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Setup StableDiffusion Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b6d9d8-6908-4dae-9310-e11c9ec07cf9",
   "metadata": {},
   "source": [
    "- There are different checkpoints / models available for text2img inferencing from HuggingFace. In this notebook, we would be using ``CompVis/stable-diffusion-v1-4``. The other variations of the model can be found [here](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/text2img)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad789d7-525b-42b4-87c4-689c922b4c89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"CompVis/stable-diffusion-v1-4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ce9c05-6683-4283-a4b8-a4df1f13b740",
   "metadata": {},
   "source": [
    "- To generate User access tokens, please go through the link [here](https://huggingface.co/docs/hub/security-tokens) and source it as a ``AUTH_TOKEN`` environment variable while building the docker container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6ba767-7f8a-4d9e-82a3-c08f97dfdabb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "token = os.environ.get('AUTH_TOKEN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acec2567-ab95-4abc-b5a5-f71bfa64e8d5",
   "metadata": {},
   "source": [
    "- Since we are limited by the GPU RAM, StableDiffusionPipeline is loaded in ``float16`` precision by loading the weights from ``fp16`` branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbfed23-f24b-4b3a-8a24-8c070c3631d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    model_id,\n",
    "    revision=\"fp16\",\n",
    "    torch_dtype=torch.float16,\n",
    "    use_auth_token = token\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506ea2ed-9bf3-4f3b-ac9b-97de1dc9e922",
   "metadata": {
    "tags": []
   },
   "source": [
    "- Moving the diffusion pipeline to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8dfefc-28d5-4813-805b-73627c6834fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe = pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8051b5fa-015c-41ac-873d-64aa18995cfb",
   "metadata": {},
   "source": [
    "### 3. Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264bd509-0c49-4eb7-9e71-7442e8dacf6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"a photograph of an astronaut riding a horse\"\n",
    "image = pipe(prompt).images[0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee11975-ff99-40f2-85f7-576490e8d10c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = pipe(prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ee81b3-7d11-42dc-b49c-cdca219cf269",
   "metadata": {},
   "source": [
    "- The above model would return different output for the same prompt. To get the same image output, we use a generator with a set manual seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa89ade-af29-4d5f-b513-12b59a0df36a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator = torch.Generator(device=\"cuda\").manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67ed1bc-d5d5-4c0d-a4fc-f9220d267ccb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image = pipe(\n",
    "    prompt, \n",
    "    generator=generator\n",
    ").images[0]\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aa02c0-fe35-4a27-b182-b283f712bb8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "- ``num_inference_steps`` can be changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce324d1-1774-45ed-b90b-94d5d092af85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image = pipe(\n",
    "    prompt, \n",
    "    num_inference_steps=15, \n",
    "    generator=generator\n",
    ").images[0]\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253a279e-d17d-4f24-81ae-feeef5965462",
   "metadata": {},
   "source": [
    "- guidance scale:\n",
    "It is a way to increase the adherence to the conditional signal which in this case is text as well as overall sample quality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2821e69f-2c35-4b58-95f2-78200be85494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image = pipe(\n",
    "    prompt, \n",
    "    guidance_scale=7.5, \n",
    "    generator=generator\n",
    ").images[0]\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162e1c69-dd04-46ea-ac19-dbdbae6ca7a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "- creating grid of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bed1d7-dda4-42f6-9286-52f29c1957de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "def image_grid(imgs, rows, cols):\n",
    "    assert len(imgs) == rows*cols\n",
    "\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "    grid_w, grid_h = grid.size\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e285eeb-68af-4dda-bfe3-06ce902b1ea3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_images = 3\n",
    "prompt = [\"a photograph of an astronaut riding a horse\"] * num_images\n",
    "\n",
    "images = pipe(prompt).images\n",
    "\n",
    "grid = image_grid(images, rows=1, cols=3)\n",
    "grid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
